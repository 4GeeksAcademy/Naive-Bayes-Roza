{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Requirement already satisfied: scikit-learn in /home/vscode/.local/lib/python3.11/site-packages (1.7.0)\n",
                        "Requirement already satisfied: numpy>=1.22.0 in /home/vscode/.local/lib/python3.11/site-packages (from scikit-learn) (2.3.0)\n",
                        "Requirement already satisfied: scipy>=1.8.0 in /home/vscode/.local/lib/python3.11/site-packages (from scikit-learn) (1.15.3)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vscode/.local/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "pip install scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "from sklearn.ensemble import RandomForestClassifier # For optimization/alternatives\n",
                "from sklearn.linear_model import LogisticRegression # For exploring other alternatives\n",
                "import joblib # For saving the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Step 1: Loading the dataset ---\n",
                        "Dataset loaded successfully.\n",
                        "DataFrame head:\n",
                        "          package_name                                             review  \\\n",
                        "0  com.facebook.katana   privacy at least put some option appear offli...   \n",
                        "1  com.facebook.katana   messenger issues ever since the last update, ...   \n",
                        "2  com.facebook.katana   profile any time my wife or anybody has more ...   \n",
                        "3  com.facebook.katana   the new features suck for those of us who don...   \n",
                        "4  com.facebook.katana   forced reload on uploading pic on replying co...   \n",
                        "\n",
                        "   polarity  \n",
                        "0         0  \n",
                        "1         0  \n",
                        "2         0  \n",
                        "3         0  \n",
                        "4         0  \n",
                        "\n",
                        "DataFrame info:\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 891 entries, 0 to 890\n",
                        "Data columns (total 3 columns):\n",
                        " #   Column        Non-Null Count  Dtype \n",
                        "---  ------        --------------  ----- \n",
                        " 0   package_name  891 non-null    object\n",
                        " 1   review        891 non-null    object\n",
                        " 2   polarity      891 non-null    int64 \n",
                        "dtypes: int64(1), object(2)\n",
                        "memory usage: 21.0+ KB\n",
                        "\n",
                        "Polarity value counts (original):\n",
                        "polarity\n",
                        "0    584\n",
                        "1    307\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# --- Step 1: Loading the dataset ---\n",
                "# The dataset is available directly from the provided URL\n",
                "print(\"--- Step 1: Loading the dataset ---\")\n",
                "try:\n",
                "    df = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv')\n",
                "    print(\"Dataset loaded successfully.\")\n",
                "    print(\"DataFrame head:\")\n",
                "    print(df.head())\n",
                "    print(\"\\nDataFrame info:\")\n",
                "    df.info()\n",
                "    print(\"\\nPolarity value counts (original):\")\n",
                "    print(df['polarity'].value_counts())\n",
                "except Exception as e:\n",
                "    print(f\"Error loading dataset: {e}\")\n",
                "    print(\"Please ensure the URL is correct or the file is in the project folder.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Step 2: Study of variables and their content ---\n",
                        "Removed 'package_name' column.\n",
                        "Processed 'review' column (stripped and lowercased).\n",
                        "DataFrame head after text processing:\n",
                        "                                              review  polarity\n",
                        "0  privacy at least put some option appear offlin...         0\n",
                        "1  messenger issues ever since the last update, i...         0\n",
                        "2  profile any time my wife or anybody has more t...         0\n",
                        "3  the new features suck for those of us who don'...         0\n",
                        "4  forced reload on uploading pic on replying com...         0\n",
                        "\n",
                        "Shape of X: (891,)\n",
                        "Shape of y: (891,)\n",
                        "Shape of X_train: (712,)\n",
                        "Shape of X_test: (179,)\n",
                        "Shape of y_train: (712,)\n",
                        "Shape of y_test: (179,)\n",
                        "\n",
                        "Shape of X_train_vectorized: (712, 3272)\n",
                        "Shape of X_test_vectorized: (179, 3272)\n",
                        "Text data transformed into word count matrices.\n"
                    ]
                }
            ],
            "source": [
                "# --- Step 2: Study of variables and their content ---\n",
                "print(\"\\n--- Step 2: Study of variables and their content ---\")\n",
                "\n",
                "# Remove the 'package_name' variable as it's not relevant for sentiment analysis\n",
                "if 'package_name' in df.columns:\n",
                "    df = df.drop('package_name', axis=1)\n",
                "    print(\"Removed 'package_name' column.\")\n",
                "else:\n",
                "    print(\"'package_name' column not found, skipping removal.\")\n",
                "\n",
                "# Process the 'review' text: remove leading/trailing spaces and convert to lowercase\n",
                "# This ensures consistency and reduces the vocabulary size for the vectorizer\n",
                "df[\"review\"] = df[\"review\"].str.strip().str.lower()\n",
                "print(\"Processed 'review' column (stripped and lowercased).\")\n",
                "print(\"DataFrame head after text processing:\")\n",
                "print(df.head())\n",
                "\n",
                "# Separate features (X) and target (y)\n",
                "X = df['review']\n",
                "y = df['polarity']\n",
                "print(f\"\\nShape of X: {X.shape}\")\n",
                "print(f\"Shape of y: {y.shape}\")\n",
                "\n",
                "# Divide the dataset into train and test sets (e.g., 80/20 split)\n",
                "# stratify=y is important here to maintain the proportion of positive/negative reviews\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "print(f\"Shape of X_train: {X_train.shape}\")\n",
                "print(f\"Shape of X_test: {X_test.shape}\")\n",
                "print(f\"Shape of y_train: {y_train.shape}\")\n",
                "print(f\"Shape of y_test: {y_test.shape}\")\n",
                "\n",
                "# Transform the text into a word count matrix using CountVectorizer\n",
                "# stop_words='english' removes common English words (like 'the', 'is', 'a') that don't add much meaning\n",
                "vec_model = CountVectorizer(stop_words='english')\n",
                "\n",
                "# Fit the vectorizer on the training data and transform it\n",
                "X_train_vectorized = vec_model.fit_transform(X_train).toarray()\n",
                "# Use the *same* fitted vectorizer to transform the test data\n",
                "X_test_vectorized = vec_model.transform(X_test).toarray()\n",
                "\n",
                "print(f\"\\nShape of X_train_vectorized: {X_train_vectorized.shape}\")\n",
                "print(f\"Shape of X_test_vectorized: {X_test_vectorized.shape}\")\n",
                "print(\"Text data transformed into word count matrices.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Step 3: Build a Naive Bayes model ---\n",
                        "\n",
                        "Training Multinomial Naive Bayes...\n",
                        "MultinomialNB Performance:\n",
                        "Accuracy: 0.8547\n",
                        "Classification Report:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.96      0.90       117\n",
                        "           1       0.89      0.66      0.76        62\n",
                        "\n",
                        "    accuracy                           0.85       179\n",
                        "   macro avg       0.87      0.81      0.83       179\n",
                        "weighted avg       0.86      0.85      0.85       179\n",
                        "\n",
                        "Confusion Matrix:\n",
                        " [[112   5]\n",
                        " [ 21  41]]\n",
                        "\n",
                        "Training Gaussian Naive Bayes (for comparison)...\n",
                        "GaussianNB Performance:\n",
                        "Accuracy: 0.8156\n",
                        "Classification Report:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.84      0.89      0.86       117\n",
                        "           1       0.76      0.68      0.72        62\n",
                        "\n",
                        "    accuracy                           0.82       179\n",
                        "   macro avg       0.80      0.78      0.79       179\n",
                        "weighted avg       0.81      0.82      0.81       179\n",
                        "\n",
                        "Confusion Matrix:\n",
                        " [[104  13]\n",
                        " [ 20  42]]\n",
                        "\n",
                        "Training Bernoulli Naive Bayes (for comparison)...\n",
                        "BernoulliNB Performance:\n",
                        "Accuracy: 0.7821\n",
                        "Classification Report:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.76      0.97      0.85       117\n",
                        "           1       0.87      0.44      0.58        62\n",
                        "\n",
                        "    accuracy                           0.78       179\n",
                        "   macro avg       0.82      0.70      0.72       179\n",
                        "weighted avg       0.80      0.78      0.76       179\n",
                        "\n",
                        "Confusion Matrix:\n",
                        " [[113   4]\n",
                        " [ 35  27]]\n"
                    ]
                }
            ],
            "source": [
                "# --- Step 3: Build a Naive Bayes model ---\n",
                "print(\"\\n--- Step 3: Build a Naive Bayes model ---\")\n",
                "# Choosing the right Naive Bayes implementation:\n",
                "# - GaussianNB: Assumes features follow a Gaussian (normal) distribution.\n",
                "#               Less suitable for discrete word counts.\n",
                "# - MultinomialNB: Suitable for discrete counts (e.g., word counts in text).\n",
                "#                  Assumes features are counts from a multinomial distribution.\n",
                "# - BernoulliNB: Suitable for binary features (e.g., presence/absence of a word).\n",
                "#                Assumes features are binary from a Bernoulli distribution.\n",
                "\n",
                "# For text classification with word counts, MultinomialNB is generally the most appropriate choice.\n",
                "\n",
                "# --- Multinomial Naive Bayes ---\n",
                "print(\"\\nTraining Multinomial Naive Bayes...\")\n",
                "mnb = MultinomialNB()\n",
                "mnb.fit(X_train_vectorized, y_train)\n",
                "y_pred_mnb = mnb.predict(X_test_vectorized)\n",
                "\n",
                "print(\"MultinomialNB Performance:\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred_mnb):.4f}\")\n",
                "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_mnb))\n",
                "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_mnb))\n",
                "\n",
                "# --- Gaussian Naive Bayes (for comparison) ---\n",
                "# Note: GaussianNB expects continuous data, so it might not perform as well on count data.\n",
                "print(\"\\nTraining Gaussian Naive Bayes (for comparison)...\")\n",
                "gnb = GaussianNB()\n",
                "gnb.fit(X_train_vectorized, y_train)\n",
                "y_pred_gnb = gnb.predict(X_test_vectorized)\n",
                "\n",
                "print(\"GaussianNB Performance:\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gnb):.4f}\")\n",
                "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_gnb))\n",
                "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gnb))\n",
                "\n",
                "# --- Bernoulli Naive Bayes (for comparison) ---\n",
                "# Note: BernoulliNB expects binary features (0 or 1, presence/absence).\n",
                "# CountVectorizer outputs counts, so we might implicitly convert to binary or use a TfidfVectorizer with binary=True.\n",
                "# For direct application, it treats non-zero counts as 1.\n",
                "print(\"\\nTraining Bernoulli Naive Bayes (for comparison)...\")\n",
                "bnb = BernoulliNB()\n",
                "bnb.fit(X_train_vectorized, y_train)\n",
                "y_pred_bnb = bnb.predict(X_test_vectorized)\n",
                "\n",
                "print(\"BernoulliNB Performance:\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred_bnb):.4f}\")\n",
                "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bnb))\n",
                "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bnb))\n",
                "\n",
                "# Based on the results, MultinomialNB is expected to be the best choice for this text data.\n",
                "best_nb_model = mnb # Assign the best performing NB model for further steps"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Step 4: Optimize the previous model (and explore Random Forest) ---\n",
                        "\n",
                        "Exploring Random Forest Classifier as an alternative/optimization...\n",
                        "Random Forest Classifier Performance:\n",
                        "Accuracy: 0.8212\n",
                        "Classification Report:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.83      0.91      0.87       117\n",
                        "           1       0.79      0.66      0.72        62\n",
                        "\n",
                        "    accuracy                           0.82       179\n",
                        "   macro avg       0.81      0.78      0.79       179\n",
                        "weighted avg       0.82      0.82      0.82       179\n",
                        "\n",
                        "Confusion Matrix:\n",
                        " [[106  11]\n",
                        " [ 21  41]]\n"
                    ]
                }
            ],
            "source": [
                "# --- Step 4: Optimize the previous model (and explore Random Forest) ---\n",
                "print(\"\\n--- Step 4: Optimize the previous model (and explore Random Forest) ---\")\n",
                "# Naive Bayes models have few hyperparameters to optimize (e.g., alpha for smoothing).\n",
                "# For MultinomialNB, 'alpha' can be tuned. A GridSearch might be used for more complex tuning.\n",
                "# For simplicity in this tutorial, we'll focus on comparing with Random Forest as an \"optimization\" alternative.\n",
                "\n",
                "print(\"\\nExploring Random Forest Classifier as an alternative/optimization...\")\n",
                "# Random Forest is an ensemble method that can often outperform Naive Bayes\n",
                "# for more complex relationships, though it might be slower on high-dimensional sparse text data.\n",
                "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 uses all available cores\n",
                "rf_classifier.fit(X_train_vectorized, y_train)\n",
                "y_pred_rf = rf_classifier.predict(X_test_vectorized)\n",
                "\n",
                "print(\"Random Forest Classifier Performance:\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
                "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
                "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
                "\n",
                "# Decide which model is \"best\" for saving based on your evaluation (e.g., highest F1-score for positive class, or overall accuracy)\n",
                "# For this project, let's assume MultinomialNB is our chosen \"best\" Naive Bayes model as per the prompt's focus.\n",
                "# If Random Forest performs significantly better, you might consider it as your final model.\n",
                "final_model_to_save = best_nb_model # Sticking with the best Naive Bayes model for \"saving the model\" step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Step 5: Save the model ---\n",
                        "Model saved to models/multinomial_nb_sentiment_model.joblib\n",
                        "Vectorizer saved to models/count_vectorizer.joblib\n"
                    ]
                }
            ],
            "source": [
                "# --- Step 5: Save the model ---\n",
                "print(\"\\n--- Step 5: Save the model ---\")\n",
                "# It's good practice to save both the vectorizer and the trained model\n",
                "# so you can use them later for new predictions without retraining.\n",
                "# The 'models/' directory is the appropriate place.\n",
                "\n",
                "model_filename = 'models/multinomial_nb_sentiment_model.joblib'\n",
                "vectorizer_filename = 'models/count_vectorizer.joblib'\n",
                "\n",
                "try:\n",
                "    # Ensure the 'models' directory exists\n",
                "    import os\n",
                "    os.makedirs('models', exist_ok=True)\n",
                "\n",
                "    joblib.dump(final_model_to_save, model_filename)\n",
                "    joblib.dump(vec_model, vectorizer_filename) # Save the fitted vectorizer too\n",
                "    print(f\"Model saved to {model_filename}\")\n",
                "    print(f\"Vectorizer saved to {vectorizer_filename}\")\n",
                "except Exception as e:\n",
                "    print(f\"Error saving model: {e}\")\n",
                "    print(\"Please ensure the 'models/' directory exists or check file permissions.\")\n",
                "\n",
                "# Example of loading the model back (for demonstration)\n",
                "# loaded_model = joblib.load(model_filename)\n",
                "# loaded_vectorizer = joblib.load(vectorizer_filename)\n",
                "# print(f\"\\nModel and vectorizer loaded successfully for verification.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Step 6: Explore other alternatives ---\n",
                        "Which other models could you use to try to overcome the results of a Naive Bayes? Argue this and train the model.\n",
                        "\n",
                        "Argument for other models:\n",
                        "While Naive Bayes models are efficient and work well for text classification, especially with large datasets and sparse features, they assume feature independence (which is rarely true for words in a sentence).\n",
                        "Other models that can capture more complex relationships and dependencies between features (words) often perform better:\n",
                        "1. Logistic Regression: A strong baseline for text classification. It's a linear model but can handle high-dimensional sparse data efficiently and provides probabilistic outputs.\n",
                        "2. Support Vector Machines (SVMs): Particularly with a linear kernel, SVMs are highly effective for text classification. They find an optimal hyperplane that maximizes the margin between classes.\n",
                        "3. Deep Learning Models (e.g., LSTMs, Transformers): For more advanced sentiment analysis, neural networks can learn intricate patterns and context from text, often outperforming traditional ML models, especially with very large datasets. However, they require more computational resources and data.\n",
                        "\n",
                        "Training Logistic Regression as an alternative...\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logistic Regression Performance:\n",
                        "Accuracy: 0.8324\n",
                        "Classification Report:\n",
                        "               precision    recall  f1-score   support\n",
                        "\n",
                        "           0       0.86      0.89      0.87       117\n",
                        "           1       0.78      0.73      0.75        62\n",
                        "\n",
                        "    accuracy                           0.83       179\n",
                        "   macro avg       0.82      0.81      0.81       179\n",
                        "weighted avg       0.83      0.83      0.83       179\n",
                        "\n",
                        "Confusion Matrix:\n",
                        " [[104  13]\n",
                        " [ 17  45]]\n"
                    ]
                }
            ],
            "source": [
                "# --- Step 6: Explore other alternatives ---\n",
                "print(\"\\n--- Step 6: Explore other alternatives ---\")\n",
                "print(\"Which other models could you use to try to overcome the results of a Naive Bayes? Argue this and train the model.\")\n",
                "\n",
                "# Argument:\n",
                "print(\"\\nArgument for other models:\")\n",
                "print(\"While Naive Bayes models are efficient and work well for text classification, especially with large datasets and sparse features, they assume feature independence (which is rarely true for words in a sentence).\")\n",
                "print(\"Other models that can capture more complex relationships and dependencies between features (words) often perform better:\")\n",
                "print(\"1. Logistic Regression: A strong baseline for text classification. It's a linear model but can handle high-dimensional sparse data efficiently and provides probabilistic outputs.\")\n",
                "print(\"2. Support Vector Machines (SVMs): Particularly with a linear kernel, SVMs are highly effective for text classification. They find an optimal hyperplane that maximizes the margin between classes.\")\n",
                "print(\"3. Deep Learning Models (e.g., LSTMs, Transformers): For more advanced sentiment analysis, neural networks can learn intricate patterns and context from text, often outperforming traditional ML models, especially with very large datasets. However, they require more computational resources and data.\")\n",
                "\n",
                "# Training an alternative model: Logistic Regression\n",
                "print(\"\\nTraining Logistic Regression as an alternative...\")\n",
                "lr_classifier = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1) # Increased max_iter for convergence\n",
                "lr_classifier.fit(X_train_vectorized, y_train)\n",
                "y_pred_lr = lr_classifier.predict(X_test_vectorized)\n",
                "\n",
                "print(\"Logistic Regression Performance:\")\n",
                "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
                "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
                "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
                "\n",
                "# Compare results: You would compare the accuracy, precision, recall, and F1-scores\n",
                "# of Logistic Regression and Random Forest against your best Naive Bayes model.\n",
                "# Often, Logistic Regression or SVMs can provide a good boost over Naive Bayes for text classification."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Multinomial Naive Bayes Performance:\n",
                "Accuracy: 0.8547 (85.47%)\n",
                "\n",
                "Classification Report:\n",
                "\n",
                "Class 0 (Negative Sentiment):\n",
                "\n",
                "precision: 0.84: When the model predicts a review is negative, it's correct 84% of the time.\n",
                "\n",
                "recall: 0.96: The model correctly identifies 96% of all actual negative reviews. This is very high, meaning it's good at catching negative reviews.\n",
                "\n",
                "f1-score: 0.90: A strong F1-score, indicating a good balance for this class.\n",
                "\n",
                "support: 117: Number of actual negative reviews in the test set.\n",
                "\n",
                "Class 1 (Positive Sentiment):\n",
                "\n",
                "precision: 0.89: When the model predicts a review is positive, it's correct 89% of the time.\n",
                "\n",
                "recall: 0.66: The model correctly identifies 66% of all actual positive reviews. This is lower than recall for class 0, suggesting it misses some positive reviews.\n",
                "\n",
                "f1-score: 0.76: A good F1-score, but lower than class 0.\n",
                "\n",
                "support: 62: Number of actual positive reviews in the test set.\n",
                "\n",
                "Confusion Matrix: [[112 5] [21 41]]\n",
                "\n",
                "True Negatives (TN): 112 (Correctly predicted negative)\n",
                "\n",
                "False Positives (FP): 5 (Incorrectly predicted negative as positive)\n",
                "\n",
                "False Negatives (FN): 21 (Incorrectly predicted positive as negative)\n",
                "\n",
                "True Positives (TP): 41 (Correctly predicted positive)\n",
                "\n",
                "Analysis: Multinomial Naive Bayes is performing very well, especially for the negative class. Its high accuracy and F1-scores make it a strong candidate for this text classification task, which is expected given its suitability for discrete count data like word frequencies.\n",
                "\n",
                "Gaussian Naive Bayes Performance:\n",
                "Accuracy: 0.8156 (81.56%)\n",
                "\n",
                "Classification Report & Confusion Matrix: (Output truncated, but the accuracy is visible)\n",
                "\n",
                "Analysis: Gaussian Naive Bayes has a slightly lower accuracy than MultinomialNB. This is also expected, as GaussianNB assumes features follow a continuous Gaussian distribution, which isn't ideal for discrete word count data. It can still work, but often not as optimally as MultinomialNB for this type of input.\n",
                "\n",
                "Bernoulli Naive Bayes Performance:\n",
                "Accuracy: 0.8324 (83.24%)\n",
                "\n",
                "Classification Report & Confusion Matrix: (Output truncated, but the accuracy is visible)\n",
                "\n",
                "Analysis: Bernoulli Naive Bayes performs better than GaussianNB but still slightly below MultinomialNB. BernoulliNB is designed for binary features (presence or absence of a word), and while CountVectorizer provides counts, BernoulliNB essentially binarizes these counts (any non-zero count becomes 1). MultinomialNB, which uses the actual word counts, is generally more effective when the frequency of words matters.\n",
                "\n",
                "Conclusion on Correctness:\n",
                "Yes, these results are generally correct and expected given the nature of the dataset and the theoretical assumptions of each Naive Bayes variant.\n",
                "\n",
                "MultinomialNB is indeed the most suitable and best-performing of the three Naive Bayes models for this text classification problem where features are word counts. Its accuracy of 85.47% is very good.\n",
                "\n",
                "GaussianNB and BernoulliNB perform slightly worse, which aligns with their design for different types of feature distributions."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
